# MUSS-ptBR - Simplificador textual para portugu√™s

Autor: Raphael Assis (contato.raphael.assis@gmail.com)

## Introdu√ß√£o do problema

Para entender mais sobre a tarefa de simplifica√ß√£o textual leia [este artigo](https://direct.mit.edu/coli/article/46/1/135/93384/Data-Driven-Sentence-Simplification-Survey-and).

## Infraestrutura utilizada

Para a realiza√ß√£o deste trabalho utilizou-se a plataforma [Google Cloud](https://cloud.google.com/). Esta plataforma disponibiliza todos os recursos necess√°rios para a implementa√ß√£o deste trabalho e ainda oferece 300 d√≥lares  de cr√©ditos (~1770 reais  em 08/2022) para testar os servi√ßos antes de come√ßar a pagar pela utiliza√ß√£o. Por conta disso, este trabalho pode ser replicado integralmente somente se utilizando dos cr√©ditos gratuitos oferecidos pelo Google ü§©!

A infraestrutura utilizada foi a seguinte:

M√°quina com 8 vCPUs, 52 GB de mem√≥ria (n1-highmem-8), 2 TB de HDD (disco de inicializa√ß√£o) e 1 GPU NVIDIA Tesla T4. O sistema operacional utilizado foi o Ubuntu 20.04 LTS para arquitetura x86 de 64 bits. Essa configura√ß√£o resulta em um custo de US$ 0,69 por hora.

Obs: O disco de inicializa√ß√£o n√£o precisa possuir tanto volume de armazenamento. √â poss√≠vel economizar ainda mais utilizando um disco separado para manter os dados da VM e utilizar um disco de inicializa√ß√£o de uns 10Gb. Voc√™ pode ver mais detalhes sobre isso [neste tutorial](https://cloud.google.com/compute/docs/disks/add-persistent-disk?hl=pt-br). Entretanto, ao utilizar um disco de inicializa√ß√£o com bastante volume de armazenamento h√° menos configura√ß√µes para realizar na VM. 

## Configura√ß√£o do projeto na VM

Ap√≥s criar e iniciar a VM √© preciso clonar o projeto do Github e configurar as depend√™ncias do projeto. Al√©m disso, como a VM inicia com uma imagem limpa do Linux √© necess√°rio atualizar alguns programas. Os passos necess√°rios s√£o os seguintes:

1. Execute `sudo apt-get update`
2. Execute `sudo apt-get install python3-pip`
3. Execute `sudo apt-get install zip`
4. Execute `sudo apt install unzip`
5. Execute `sudo apt install python3.8-venv`
6. Execute `sudo apt-get install build-essential cmake`
7. Execute `sudo apt install build-essential cmake libboost-system-dev libboost-thread-dev libboost-program-options-dev libboost-test-dev libeigen3-dev zlib1g-dev libbz2-dev liblzma-dev`
8. Clone o c√≥digo do Github: `git clone git@github.com:facebookresearch/muss.git`
9. Navegue at√© a pasta do projeto: `cd muss/`
10. Execute `pip install -e .`
11. Siga [este tutorial](https://cloud.google.com/compute/docs/gpus/install-drivers-gpu?hl=pt-br#verify-driver-install) para instalar os drivers da GPU na VM.
12. Siga [este tutorial](https://cloud.google.com/compute/docs/gpus/monitor-gpus#use-virtualenv_1) para configurar a telemetria da GPU na VM e poder monitorar seu desempenho durante a execu√ß√£o dos treinamentos do modelo.
13. Suba os arquivos com o corpus de texto para a VM. Veja [este tutorial](https://cloud.google.com/compute/docs/instances/transfer-files?hl=pt-br#upload-to-the-vm) de como enviar e receber arquivos para a VM. A pasta onde os arquivos ser√£o salvos n√£o importa (por padr√£o √© uma pasta com o seu nome de usu√°rio em \home), pois o muss recebe o path como par√¢metro.

Ap√≥s realizar todos os passos acima, a VM estar√° configurada e pronta para o uso. 

## Adaptando o muss para um novo idioma

O Multilingual Unsupervised Sentence Simplification (MUSS) √© um modelo de linguagem baseado em BART e mBART que realiza simplifica√ß√£o textual. Neste projeto, h√° tanto scripts para produzir uma base de dados de par√°frases para o treinamento do modelo quanto scripts para treinar e avaliar o modelo.

### Fase de minera√ß√£o de par√°frases

Nesta fase, realiza-se o pr√©-processamento dos textos coletados e produ√ß√£o de par√°frases para realizar o treinamento do modelo. O objetivo desta fase √© obter pares de frases com representem a vers√£o complexa e simplificada de uma senten√ßa. O resultado dessa fase √© uma pasta com os arquivos  test.complex, test.simple, train.complex, train.simple, valid.complex e valid.simple. Ambos arquivos s√£o no formato txt, sendo cada linha composta por uma uma senten√ßa. Dessa forma, a senten√ßa da linha 1 do arquivo test.complex √© a vers√£o complexa da senten√ßa da linha 1 do arquivo test.simple.

Exemplo de arquivo com senten√ßas complexas: 

```
Um lado dos conflitos armados √© composto principalmente pelos militares sudaneses e pelos Janjaweed, um grupo de mil√≠cias sudanesas recrutado principalmente das tribos afro-√°rabes Abbala da regi√£o norte de Rizeigat, no Sud√£o.
Jeddah √© a principal porta de entrada para Meca, a cidade mais sagrada do Isl√£, que os mu√ßulmanos s√£os s√£o obrigados a visitar pelo menos uma vez na vida.
Acredita-se que a Grande Mancha Escura represente um buraco no conv√©s de nuvens de metano de Netuno.
Seu pr√≥ximo trabalho, s√°bado, segue um dia especialmente agitado na vida de um neurocirurgi√£o de sucesso.
A tar√¢ntula, o personagem trapaceiro, girou uma corda preta e, prendendo-a √† bola, rastejou rapidamente para o leste, puxando a corda com toda a for√ßa.
L√° ele morreu seis semanas depois, em 13 de janeiro de 888.
Eles s√£o culturalmente semelhantes aos povos costeiros de Papua Nova Guin√©.
```

Exemplo de arquivo com senten√ßas simples: 

```
Um lado da guerra √© composto principalmente pelos militares sudaneses e pelos Janjaweed. O Janjaweed √© um grupo de mil√≠cia sudanesa que vem principalmente das tribos afro-√°rabes Abbala da regi√£o norte de Rizeigat, no Sud√£o.
Jeddah √© a porta de entrada para Meca, a cidade mais sagrada do Isl√£, que os mu√ßulmanos devem visitar uma vez na vida.
Acredita-se que a Grande Mancha Escura seja um buraco nas nuvens de metano de Netuno.
S√°bado segue um dia agitado na vida de um neurocirurgi√£o.
A tar√¢ntula, que √© complicada, girou um cord√£o preto para se juntar a uma bola e pux√°-la para o leste com toda a sua for√ßa.
Ele morreu l√° seis semanas depois, em 13 de janeiro de 888.
Eles s√£o semelhantes ao povo da Papua Nova Guin√© que vive na costa.
```

Para iniciar essa fase √© necess√°rio obter uma base de dados de textos para produzir as par√°frases de treinamento. No projeto original, utilizou-se textos minerados pelo programa [ccnet](https://github.com/facebookresearch/cc_net), que minera textos do Common Crawl. Recomendamos utiliz√°-lo para extra√ß√£o destes textos, pois ele garante que os textos coletados ser√£o de alta qualidade. Entretanto, n√£o √© obrigat√≥rio sua utiliza√ß√£o. O muss apenas espera que o formato dos textos de entrada sejam similares aos shards que o ccnet gera.

O formato dos arquivos de entrada do script de minera√ß√£o de par√°frases √© um conjunto de JSONs separados por quebra de linha, sendo a √∫ltima linha do arquivo vazia. Cada JSON precisa conter o campo `raw_content` com o texto que deve ser processado. O ccnet fornece mais dados al√©m deste, por√©m o muss s√≥ espera este campo.

Exemplo de shard gerado pelo ccnet:

```
{"url": "http://aapsocidental.blogspot.com/2018/05/autoridades-de-ocupacao-marroquinas.html", "date_download": "2019-01-16T00:32:20Z", "digest": "sha1:G4UHEYCPVGMKCO37M67XGN7Y5QJ7U7GM", "length": 2022, "nlines": 10, "source_domain": "aapsocidental.blogspot.com", "title": "Sahara Ocidental Informa√ß√£o: Autoridades de ocupa√ß√£o marroquinas transferem arbitrariamente o ativista saharaui Hassanna Duihi", "raw_content": "Autoridades de ocupa√ß√£o marroquinas transferem arbitrariamente o ativista saharaui Hassanna Duihi\n27 de maio, 2018 - Liga para la Protecci√≥n de los Presos Saharauis en las c√°rceles marroqu√≠es - As autoridades de ocupa√ß√£o marroquinas tomaram a decis√£o de transferir arbitrariamente o vice-presidente da Liga para a Prote√ß√£o dos Presos Saharauis em c√°rceres marroquinos, Hassanna Duihi, de El Aai√∫n para a cidade ocupada de Bojador, ap√≥s a senten√ßa proferida pelo Tribunal de Apela√ß√£o em Marraquexe, apesar da senten√ßa do tribunal de primeira inst√¢ncia tenha decretado a anula√ß√£o da decis√£o da transfer√™ncia arbitr√°ria..", "cc_segment": "crawl-data/CC-MAIN-2019-04/segments/1547583656530.8/wet/CC-MAIN-20190115225438-20190116011438-00000.warc.wet.gz", "original_nlines": 290, "original_length": 13580, "line_ids": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "language": "pt", "language_score": 0.96, "perplexity": 157.6, "bucket": "head"}
{"url": "http://aguaslindasdegoias.go.gov.br/2018/11/22/", "date_download": "2019-01-15T23:49:20Z", "digest": "sha1:FIBOHPZ7BYGPBRTEFUHQJB7UMBEKPVGK", "length": 309, "nlines": 2, "source_domain": "aguaslindasdegoias.go.gov.br", "title": "√Åguas Lindas de Goi√°s | 2018 novembro 22", "raw_content": "Preg√£o n¬∞ 051/2018 ‚Äì Sele√ß√£o da melhor proposta para a aquisi√ß√£o de brita, emuls√£o RR-1C, conforme especifica√ß√µes previstas no termo de Refer√™ncia\nPreg√£o n¬∞ 054/2018 ‚Äì Aquisi√ß√£o de c√¢maras fotogr√°ficas digitais que ser√£o utilizados pela Secretaria Municipal de Habita√ß√£o e Integra√ß√£o Fundi√°ria deste munic√≠pio", "cc_segment": "crawl-data/CC-MAIN-2019-04/segments/1547583656530.8/wet/CC-MAIN-20190115225438-20190116011438-00000.warc.wet.gz", "original_nlines": 182, "original_length": 4288, "line_ids": [96, 102], "language": "pt", "language_score": 1.0, "perplexity": 66.7, "bucket": "head"}
{"url": "http://alvopesquisas.com.br/ipixunadopara.asp", "date_download": "2019-01-16T00:17:51Z", "digest": "sha1:3YRVHGS4JQBJ5YWXOTIPT7XX7TJB3U4T", "length": 1232, "nlines": 5, "source_domain": "alvopesquisas.com.br", "title": "Bem-vindo √† @lvo Pesquisas!!!", "raw_content": "Em 1958 chegou √† regi√£o o pioneiro Manoel do Carmo, que, juntamente com sua fam√≠lia, utilizou a via fluvial. O primeiro passo foi construir uma morada e, em seguida o ro√ßado. No seu rastro vieram Irineu Farias, Antonio Cipriano e Manoel Henrique.\nNa esteira do pioneirismo surgiu a primeira casa de com√©rcio,em 1960, de Vicente Fortunato. Instalado em 01 de janeiro de 1993.", "cc_segment": "crawl-data/CC-MAIN-2019-04/segments/1547583656530.8/wet/CC-MAIN-20190115225438-20190116011438-00000.warc.wet.gz", "original_nlines": 75, "original_length": 2459, "line_ids": [51, 52, 53, 54, 55], "language": "pt", "language_score": 0.97, "perplexity": 89.1, "bucket": "head"}
{"url": "http://azeitedoalentejo.pt/cepaal/", "date_download": "2019-01-15T23:41:11Z", "digest": "sha1:EH2JEC2BSIVKJU5GPXU6IYRXX7DZWYF4", "length": 1337, "nlines": 10, "source_domain": "azeitedoalentejo.pt", "title": "CEPAAL ‚Äì Azeite do Alentejo", "raw_content": "O CEPAAL\nO CEPAAL ‚Äì Centro de Estudos e Promo√ß√£o do Azeite do Alentejo nasceu em 1999 e √© uma associa√ß√£o sem fins lucrativos, sedeada em Moura, que tem como objetivo valorizar e promover o Azeite do Alentejo dentro e fora de Portugal.\nTem entre os seus associados 26 produtores e 13 institui√ß√µes ligadas ao sector oliv√≠cola e ole√≠cola, incluindo organismos do Estado, munic√≠pios e universidades.\nNo √¢mbito das suas atividades, desenvolve a√ß√µes de promo√ß√£o do Azeite do Alentejo e √© a entidade respons√°vel pela organiza√ß√£o do Concurso Nacional de Azeites de Portugal, integrado na Feira Nacional de Agricultura, e pelo Concurso de Azeite Virgem da Feira Nacional de Olivicultura, sendo tamb√©m a entidade respons√°vel pela organiza√ß√£o do Congresso Nacional do Azeite.", "cc_segment": "crawl-data/CC-MAIN-2019-04/segments/1547583656530.8/wet/CC-MAIN-20190115225438-20190116011438-00000.warc.wet.gz", "original_nlines": 147, "original_length": 4332, "line_ids": [16, 19, 20, 21, 23, 25, 27, 28, 56, 84], "language": "pt", "language_score": 0.98, "perplexity": 169.4, "bucket": "head"}

```

Exemplo de shard gerado manualmente:

```
{"raw_content": "Tempo de Entrega At√© 2 dias ap√≥s confirma√ß√£o de pagamento\n1. O prazo de validade para a utiliza√ß√£o do Vale Presente √© de 03 meses (Tr√™s meses) a contar da data de sua compra, que constar√° do e-mail enviado pela Loja Soma de Dois, ao cliente ap√≥s a confirma√ß√£o do pagamento.\n2. O Vale Presente consiste num c√≥digo que ser√° enviado ao cliente por e-mail, de acordo com seu cadastro no site da Loja Soma de Dois (https://somadedois.com.br), indicando o valor, a data da compra, o c√≥digo que dever√° ser utilizado e o link relativo a este regulamento de utiliza√ß√£o.\n3."}
{"raw_content": "Um rotor de elevado desempenho com a diversidade e efici√™ncia para qualquer local\nUtilize uma chave de fendas ou a chave Hunter para, de forma f√°cil e simples, ajustar o arco de irriga√ß√£o conforme necess√°rio.\nO FloStop fecha a vaz√£o de √°gua dos aspersores individualmente enquanto o sistema continua a funcionar. Esta situa√ß√£o √© ideal para a substitui√ß√£o de bocais ou para desligar aspersores espec√≠ficos durante trabalhos de manuten√ß√£o e/ou instala√ß√£o."}
{"raw_content": "LEI ORG√ÇNICA DO MUNIC√çPIO DE BOM CONSELHO 1990\nSe√ß√£o I ‚Äì Disposi√ß√µes Gerais 1¬∞ a 4¬∞\nSe√ß√£o II ‚Äì Da Divis√£o Administrativa do Munic√≠pio 5¬∞ a 9¬∞\nCap. II ‚Äì Da Compet√™ncia do Munic√≠pio 10 a 13\nSe√ß√£o II ‚Äì Da Compet√™ncia Comum 11 a 13\nT√çT. II ‚Äì DA ORGANIZA√á√ÉO DOS PODERES 15 A 89\nCap. I ‚Äì Do Poder Legislativo 15 a 69\nSe√ß√£o I ‚Äì Da C√¢mara Municipal 15 a 16\nSe√ß√£o II ‚Äì Das Atribui√ß√µes da C√¢mara Municipal 17 a 18\nSe√ß√£o III ‚Äì Do Funcionamento da C√¢mara 19 a 32\nSe√ß√£o V ‚Äì Das Comiss√µes 39 a 40\nSe√ß√£o VI ‚Äì Do Processo Legislativo 41 a 56\nSub. I ‚Äì Disposi√ß√µes Gerais 41 a 42\nSub. II ‚Äì Das Emendas √† Lei Org√¢nica 43\nSub. IV ‚Äì Dos Decretos legislativos e das Resolu√ß√µes 55 a 56\nSe√ß√£o VIII ‚Äì Dos Vereadores 59 a 69\nCap. II ‚Äì Do Poder Executivo 70 a 89\nSe√ß√£o II ‚Äì Do Prefeito e do Vice-Prefeito 73 a 78\nSe√ß√£o III ‚Äì Da Compet√™ncia do Prefeito 79 a 80\nSe√ß√£o IV ‚Äì Da responsabilidade do Prefeito 81 a 83\nSe√ß√£o V ‚Äì Dos Auxiliares Diretos do Prefeito 84 a 89\nCap. II ‚Äì Da Administra√ß√£o P√∫blica 91 a 116\nSe√ß√£o II ‚Äì Das Obras e Servi√ßos Municipais 94 a 100\nSe√ß√£o III ‚Äì Dos Bens Municipais 101 a 110\nSe√ß√£o IV ‚Äì Dos Servidores P√∫blicos 111 a 114\nSe√ß√£o V ‚Äì Da Seguran√ßa Publica 115 a 116\nCap. III ‚Äì Da Estrutura Administrativa 117\nCap. IV ‚Äì Dos atos Municipais 118 a 122\nSe√ß√£o I ‚Äì Da Publicidade dos Atos Municipais 118 a 120\nCap. I ‚Äì Dos Tributos Municipais 123 a 133\nCap. II ‚Äì Dos Pre√ßos P√∫blicos 134 a 135\n"}
{"raw_content": "√â com muita satisfa√ß√£o que come√ßo essa coluna sobre Dan√ßa e Nutri√ß√£o! Sou muito grata pelo convite da Dryelle e espero a cada semana poder trazer temas importantes para que n√≥s, bailarinos, tenhamos boa sa√∫de e bom desempenho por meio de uma alimenta√ß√£o saud√°vel e, o mais importante, sem neuras!\nVou come√ßar falando sobre a import√¢ncia da nutri√ß√£o nas modalidades de dan√ßa que, embora sejam uma linda express√£o art√≠stica, tamb√©m s√£o atividades f√≠sicas que requerem muito desempenho f√≠sico. Em geral, come√ßa-se a praticar na inf√¢ncia e na adolesc√™ncia, mas atualmente muitos adultos tamb√©m aderiram a essas modalidades.\nCada tipo de dan√ßa desenvolve aptid√µes f√≠sicas espec√≠ficas que exigem dos bailarinos resist√™ncia muscular e esquel√©tica, osteoarticular, flexibilidade, bom condicionamento cardiorrespirat√≥rio e uma composi√ß√£o corporal magra e esguia.\n"}
```

O problema em utilizar o ccnet √© que o custo computacional para minerar os textos √© bastante elevado, sendo bastante maior do que o custo necess√°rio para treinar o MUSS. Por este motivo, para o treinamento do MUSS para portugu√™s utilizou-se o dataset do ccnet compartilhado [aqui](https://data.statmt.org/cc-100/). Neste reposit√≥rio, h√° 116 arquivos contendo o conte√∫do minerado para esses idiomas. Cada arquivo √© um √∫nico txt comprido, podendo ter mais de 80Gb. O arquivo para o idioma portugu√™s cont√©m 13Gb comprimido e mais de 50Gb descomprimido. Estes arquivos s√£o formatados contendo o texto de cada site minerado pelo ccnet separados por uma linha em banco e a √∫ltima linha do arquivo √© vazia. Dessa forma, √© como se fosse um arquivo gigante onde cada par√°grafo √© o texto completo de cada site minerado.

```
Site1_Linha1
Site1_Linha2
Site1_LinhaN

Site2_Linha1
Site2_Linha2
Site2_LinhaN

SiteN_Linha1
SiteN_LinhaN

```

Para manipular este arquivo, primeiro realizou-se sua divis√£o em arquivos com 1.500.000 linhas cada utilizando a ferramenta para Windows [Text File Split](https://www.microsoft.com/store/productId/9PFNL897RKKM), totalizando 228 arquivos, por√©m pode-se utilizar qualquer script customizado para essa tarefa. Em seguida, converteu-se cada arquivo para o formato do ccnet. O script Python utilizado para realizar essa formata√ß√£o est√° ilustrado abaixo. 

```python
import json
import gzip

for i in range(1,228):
    source_file = open(f'cc100/cc100-{i}', 'r', encoding='utf-8')
    out_file = gzip.open(f'cc100_mined/pt_head_{i:04d}.json.gz', 'wt', encoding='utf-8')
    textSentence = ''
  
    while 1:   
        
        line = source_file.readline()           
        if len(line) == 0:  
            break

        if line != '\n':
            textSentence += line

        if(line == '\n'):
            textObj = {"raw_content": textSentence}
            jsonLine = json.dumps(textObj, ensure_ascii=False) + '\n'
            out_file.write(jsonLine)
            textSentence = ''
            continue

    print(f'Arquivo cc100-{i} concluido!')
    source_file.close()
    out_file.close()

print('leitura concluida com sucesso!!')
  
source_file.close()
out_file.close()
```

O funcionamento do script √© bastante simples, ele apenas abre cada shard e l√™ o texto at√© encontrar uma linha em branco; converte esse texto em um JSON adicionando o texto ao campo `raw_content` e escreve esse conte√∫do no arquivo formatado. Para executar esses passos de formata√ß√£o do dataset do ccnet para o formato esperado para o MUSS, garanta que seu computador possua armazenamento suficiente. Para o dataset de portugu√™s, foi necess√°rio em torno de 150 Gb de armazenamento para realizar essa opera√ß√£o. Ap√≥s a produ√ß√£o dos arquivos formatados pode-se deletar os demais arquivos baixados e processados. 

Ap√≥s finalizar a coleta dos textos e format√°-los corretamente, agora √© necess√°rio adaptar o c√≥digo do muss para atender ao novo idioma. Nessa fase de minera√ß√£o de par√°frases, ser√° necess√°rio alterar os arquivos `muss/scripts/mine_sequences.py`, `muss/mining/preprocessing.py` e `muss/text.py`. 

No arquivo `muss/scripts/mine_sequences.py` adicione ao objeto `n_shards`o n√∫mero de shards que deseja minerar, o que equivale ao n√∫mero de shards produzidos na formata√ß√£o discutida acima ou minerados utilizando o ccnet. Para a adapta√ß√£o para portugu√™s, utilizou-se 6 shard contendo 1.500.000 linhas cada arquivo, totalizando 9 milh√µes de linhas de texto.

No arquivo `muss/text.py` adapte as fun√ß√µes `get_spacy_model` e `get_sentence_tokenize` para o novo idioma. 

No arquivo `muss/mining/preprocessing.py` adapte a fun√ß√£o `has_low_lm_prob` ao novo idioma. Essa fun√ß√£o √© respons√°vel por filtrar as senten√ßas produzidas de acordo com um modelo de perplexidade. Essa etapa n√£o √© obrigat√≥ria, ent√£o pode-se for√ßar essa fun√ß√£o a sempre retornar o valor False, por√©m √© fortemente recomendado que seja utilizado um modelo similar para essa tarefa. Para a adapta√ß√£o para portugu√™s, utilizou-se o modelo Kenlm dispon√≠vel no [huggingface](https://huggingface.co/edugp/kenlm).

Feito isso, j√° est√° tudo pronto para executar o script `muss/scripts/mine_sequences.py.` Como esse script utiliza muitos recursos computacionais e √© bastante demorado, execute-o de forma a [n√£o depender da conex√£o SSH](https://www.linuxdescomplicado.com.br/2017/07/saiba-como-manter-um-comando-executando-mesmo-depois-de-encerrar-uma-sessao-remota-ssh.html) com a VM. Para isso utilize o comando nohup, conforme ilustrado abaixo. Ao utilizar o nohup, a sa√≠da do comando √© escrita no arquivo nohup.out. 

```bash
nohup python3 scripts/mine_sequences.py &
```

Para acompanhar a execu√ß√£o do programa, basta monitorar o desempenho da VM pela central de monitoramento da GCloud. Os processos gerados pelo script geram logs na pasta experiments, que √© criada automaticamente na primeira execu√ß√£o. Monitorando os arquivos gerados nessa pasta voc√™ conseguir√° acompanhar o processamento do script.

Esse script ir√° demorar bastante para executar e poder√° gerar alguns problemas de estouro e vazamento de mem√≥ria. Na adapta√ß√£o para portugu√™s, esse script demorou cerca de 36 horas. Algumas adapta√ß√µes precisaram ser feitas para evitar vazamentos de mem√≥ria e discuss√£o sobre isso foi feita aqui [nesta issue](https://github.com/facebookresearch/muss/issues/32). Al√©m disso, o par√¢metro `max_tokens` da fun√ß√£o `get_laser_embeddings` foi alterada para 800.

### Treinamento do modelo

Nesta fase, o objetivo √© treinar modelo mBART utilizando as par√°frases produzidas na etapa anterior. O MUSS utiliza o modelo mBART pr√© treinado e configura o treinamento utilizando o [ACCESS](https://github.com/facebookresearch/access).

Para adicionar um novo idioma, ser√° necess√°rio adaptar os arquivos `muss/fairseq/main.py, muss/mining/training.py e scripts/train_model.py`.

No arquivo `muss/fairseq/main.py` adicione o novo idioma a fun√ß√£o `get_language_from_dataset` e mude o valor da vari√°vel `TEST_DATASET`. O valor da vari√°vel TEST_DATASET deve ser o nome de um dataset manual que ser√° utilizado pelo fairseq para testar a qualidade do modelo durante o treinamento. Esse valor deve corresponder ao nome de uma pasta dentro da pasta resources/datasets que contenha os arquivos test.complex, test.simple, valid.complex e valid.simple. Esses arquivos devem ser diferentes dos gerados na fase anterior e devem ter alta qualidade. Existem diversos benchmarks p√∫blicos que podem ser utilizados para essa finalidade como o [Asset](https://github.com/facebookresearch/asset), [Alector](https://github.com/psawa/alector_corpus/tree/master/corpus), [Porsimples](https://github.com/sidleal/porsimplessent), entre outros. Escolha algum deles e traduza para o idioma desejado.

No arquivo `muss/mining/training.py`  mude o valor da vari√°vel `TEST_DATASET`igual a etapa anterior e adicione o dicion√°rio do mBART para o novo idioma ao dicion√°rio `MBART_DICT_FILENAME`. Se voc√™ utilizar o mbart pr√©-treinado em 25 idiomas, o nome do dicion√°rio ser√° ‚Äú`dict.txt`‚Äù e se utilizar o [mBART pr√©treinado em 50 idiomas](https://github.com/facebookresearch/fairseq/tree/main/examples/multilingual#mbart50-models) o valor  ser√° ‚Äú`dict.{target_lang}.txt`‚Äù (Veja a lista de target_lang [aqui](https://github.com/facebookresearch/fairseq/blob/main/examples/multilingual/ML50_langs.txt)). Como o mBART50 √© a vers√£o mais recente, recomenda-se utiliz√°-la.

No arquivo `scripts/train_model.py`, a princ√≠pio n√£o ser√° necess√°rio modificar nada, mas caso d√™ algum problema de estouro ou vazamento de mem√≥ria pode ser necess√°rio alterar os par√¢metros de configura√ß√£o. Caso j√° possua um modelo treinado voc√™ pode passar o path do modelo no par√¢metro `restore_file_path` da fun√ß√£o `get_mbart_kwargs.`

Feito isso basta executar o comando:

```bash
nohup python3 scripts/train_model.py NAME_OF_DATASET --language LANGUAGE_OF_TRANNING &
```

O treinamento do modelo em portugu√™s durou 18 horas.

### Simplifica√ß√£o de senten√ßas

Ap√≥s produzir  e treinar um modelo de simplifica√ß√£o textual, pode-se utiliz√°-lo para simplificar textos quaisquer. Para isso, ser√° necess√°rio adaptar o arquivo `muss/simplify.py.` Adicione o nome do arquivo do modelo treinado no dicion√°rio ALLOWED_MODEL_NAMES. O nome do modelo deve ser o mesmo nome da pasta que est√° dentro da pasta `muss-ptBR\resources\models` e possui os arquivos model.pt, sentencepiece.bpe.model, dict.complex.txt e dict.simple.txt. Em seguida, adicione o novo idioma nas fun√ß√µes is_model_using_mbart e get_mbart_languages_from_model. 

Feito isso, basta executar o comando:

```bash
 python3 scripts/simplify.py FILE_PATH_TO_SIMPLIFY --model-name MODEL_NAME
```

### Detalhes do procedimento de treinamento

Fase de minera√ß√£o dos dados:

- Computar os embeddings demora em torno de 36 min para cada shard
- Treinar o index demora em torno de 20 min por shard
- Criar o base index demora em torno de 46 min por shard

## ACCESS

O Controllable Sentence Simplification permite controlar 4 par√¢metros da simplifica√ß√£o realizada pelo modelo. Esses par√¢mteros variam de 0.05 a 2.00, com passo de 0.05. Os detalhes desses par√£metros pode ser consultado no [artigo original](https://arxiv.org/pdf/2005.00352.pdf) do muss.

Estes par√¢metros podem ser configurados no arquivo `muss/simplify.py` atrav√©s da vari√°vel TOKENS_RATIO. Variando esses valores o resultado da simplifica√ß√£o muda.

```python
TOKENS_RATIO = {
    "LengthRatioPreprocessor": 1.0,
    "ReplaceOnlyLevenshteinPreprocessor": 0.5,
    "WordRankRatioPreprocessor": 0.9,
    "DependencyTreeDepthRatioPreprocessor": 0.8,
}
```